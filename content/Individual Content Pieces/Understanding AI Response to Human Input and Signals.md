---
title: "Understanding AI Response to Human Input and Signals"  
date: "2024-04-05"  
author: "PlaceOS"  
type: "Video"  
topics:  
- "[[AI]]"  
- "[[Computer Vision]]"  
- "[[]]"  
- "[[]]"  
- "[[]]"  
tags:  
- "#handsignals"  
- "#humaninput"  
- "#aiinteraction"  
- "#triggeraction"  
- "#smarttechnology"  
---
If you need help, you put your hand up.

We were all taught that at a young age.

It's a simple way of interacting, using hand signals.

Now, AI can understand and interpret requests like this.

It takes human input like voice, text and even visual signals.  
And triggers an action.

**Input -> AI -> Action.**

### Media

🔗 [View Post on LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7181821113381851137)  
  
🖼 **Image Attached:**  
![LinkedIn Post Image](https://media.licdn.com/dms/image/v2/D4E05AQGfa2_71CJbCw/videocover-high/videocover-high/0/1712279442097?e=1742263200&v=beta&t=j5WkhkB7Worhmfd_V6d-X7Qr8DpS3G0bMvVxJZG3JDs)  
  
👤 **Author:** [PlaceOS](https://www.linkedin.com/in/jonathanmcfarlane/)  
🗓️ **Date:** 2024-04-05

#### Topics

[[AI]]  
[[Computer Vision]]  
[[]]  
[[]]  
[[]]

#### Hashtags

#handsignals #humaninput #aiinteraction #triggeraction #smarttechnology